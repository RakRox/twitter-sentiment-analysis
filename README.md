
# Twitter Sentiment Analysis using Machine Learning

This project performs **Sentiment Analysis on Twitter data** using **Natural Language Processing (NLP)** and **Machine Learning**.  
It classifies tweets as **Positive** or **Negative** using the **Sentiment140 dataset** and a **Logistic Regression** model.

---

## ğŸ“Œ Project Overview

- Dataset: **Sentiment140**
- Total Tweets: **1.6 Million**
- Task: Binary Classification  
  - `0` â†’ Negative Tweet  
  - `1` â†’ Positive Tweet
- Feature Extraction: **TF-IDF**
- Model Used: **Logistic Regression**
- Accuracy Achieved: **~77.6%**

---

## ğŸ› ï¸ Libraries Used

- `numpy` â€“ numerical operations
- `pandas` â€“ data handling
- `re` â€“ text cleaning using regular expressions
- `nltk` â€“ stopwords and stemming
- `scikit-learn` â€“ machine learning models and evaluation
- `pickle` â€“ saving and loading trained model
- `kaggle` â€“ dataset download

---

## ğŸ“‚ Dataset Details

- **Name:** Sentiment140
- **Source:** Kaggle
- **Labels:**
  - `0` â†’ Negative sentiment
  - `4` â†’ Positive sentiment (converted to `1`)

---

## ğŸ“¥ Dataset Download using Kaggle API

### Step 1: Install Kaggle
```
pip install kaggle
```

### Step 2: Upload Kaggle API Token
- Go to Kaggle â†’ Account â†’ Create API Token
- Upload `kaggle.json` in Google Colab

```
mkdir -p ~/.kaggle
cp kaggle.json ~/.kaggle/
chmod 600 ~/.kaggle/kaggle.json
```

### Step 3: Download Dataset
```
kaggle datasets download -d kazanova/sentiment140
```

### Step 4: Extract Dataset
```python
from zipfile import ZipFile

with ZipFile('sentiment140.zip', 'r') as zip:
    zip.extractall()
```

---

## ğŸ”„ Project Workflow (Step by Step)

### 1ï¸âƒ£ Import Required Libraries
All necessary Python, NLP, and ML libraries are imported.

---

### 2ï¸âƒ£ Load the Dataset
The CSV file is loaded into a Pandas DataFrame and column names are assigned.

```python
column_names = ['target', 'id', 'date', 'flag', 'user', 'text']
```

---

### 3ï¸âƒ£ Data Exploration
- Checked number of rows and columns
- Verified there are no missing values
- Checked sentiment label distribution

---

### 4ï¸âƒ£ Label Conversion
Original labels:
- `0` â†’ Negative
- `4` â†’ Positive

Converted to:
```
4 â†’ 1
```

---

### 5ï¸âƒ£ Text Preprocessing (Stemming)

Each tweet is processed as follows:
- Remove special characters
- Convert to lowercase
- Remove stopwords
- Apply stemming using Porter Stemmer

```python
def stemming(content):
    content = re.sub('[^a-zA-Z]', ' ', content)
    content = content.lower().split()
    content = [stemmer.stem(word) for word in content if word not in stopwords.words('english')]
    return ' '.join(content)
```

---

### 6ï¸âƒ£ Feature and Label Separation

```python
X = tdata['stemmed_content'].values
Y = tdata['target'].values
```

---

### 7ï¸âƒ£ Train-Test Split

- 80% Training Data
- 20% Testing Data

```python
train_test_split(X, Y, stratify=Y, test_size=0.2)
```

---

### 8ï¸âƒ£ Text Vectorization using TF-IDF

```python
vectorizer = TfidfVectorizer()
X_train = vectorizer.fit_transform(X_train)
X_test = vectorizer.transform(X_test)
```

---

### 9ï¸âƒ£ Model Training (Logistic Regression)

```python
model = LogisticRegression(max_iter=1000)
model.fit(X_train, Y_train)
```

---

## ğŸ’¾ Saving the Trained Model

```python
import pickle
pickle.dump(model, open("trained_model.pkl", "wb"))
```

---

## ğŸ” Loading and Using Saved Model

```python
loaded_model = pickle.load(open("trained_model.pkl", "rb"))
```

---

## ğŸ“Š Final Results

| Metric | Score |
|------|------|
| Training Accuracy | ~79.8% |
| Testing Accuracy | ~77.6% |

---

â­ If you like this project, give the repository a star!
